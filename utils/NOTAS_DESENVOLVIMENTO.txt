================================================================================
NOTAS DE DESENVOLVIMENTO - Data Pipeline ObrasGov API
================================================================================

RESUMO DO PROJETO
-----------------
API FastAPI para consumir, processar e armazenar dados de projetos de
investimento público do Distrito Federal via API do ObrasGov.br.

Características principais:
- Estrutura de banco 100% normalizada (14 tabelas relacionadas)
- Consumo assíncrono com retry e backoff exponencial
- Sincronização automática agendada (scheduler)
- Deduplicação automática de relacionamentos
- Containers Docker (PostgreSQL + API)

================================================================================
ARQUITETURA DO BANCO DE DADOS
================================================================================

DECISÃO PRINCIPAL: Normalização vs JSONB
-----------------------------------------
Inicialmente foi proposto armazenar arrays (executores, tomadores, etc.) como
JSONB, mas após discussão decidimos pela normalização completa.

MOTIVO: "esses dados de tomadores, executores, repassadores... serão os
principais gráficos" - análises de dados são prioritárias, então normalização
facilita queries SQL e agregações.

14 TABELAS CRIADAS:
-------------------
1. projetos_investimento (tabela principal - 34 colunas + timestamps)
2. executores (id, nome, codigo)
3. tomadores (id, nome, codigo)
4. repassadores (id, nome, codigo)
5. eixos (id, descricao)
6. tipos (id, descricao, eixo_id)
7. subtipos (id, descricao, tipo_id)
8. fontes_recurso (id, projeto_id, origem, valor - One-to-Many)
9-14. projeto_executor, projeto_tomador, projeto_repassador, projeto_eixo,
      projeto_tipo, projeto_subtipo (tabelas Many-to-Many)

CAMPOS IMPORTANTES AJUSTADOS:
------------------------------
- id_unico: String(20) - máx 11 chars na API, 20 para segurança
- nome: String(350) - máx 181 chars na API, 350 para segurança
- cep: String(10) - armazena formatado (12.345-678)
- campos de texto longos: Text (endereco, descricao, funcao_social, etc)
- datas: Date (6 campos: inicial/final prevista/efetiva, cadastro, situacao)
- campos numéricos: String(50) - API retorna como string, conversão na análise
- codigo (executores/tomadores/repassadores): BigInteger (valores > 2 bilhões)

CAMPOS OPCIONAIS:
-----------------
Quase todos os campos são nullable=True, exceto:
- id_unico (chave única)
- nome (obrigatório)

================================================================================
PROBLEMAS ENCONTRADOS E SOLUÇÕES
================================================================================

1. ERRO: Integer out of range para códigos
   CAUSA: Códigos como 394676000107 ultrapassam limite do Integer
   SOLUÇÃO: Alterado de Integer para BigInteger em executores/tomadores/repassadores
   ARQUIVO: api/models.py (linhas 59, 69, 79)

2. ERRO: isModeladaPorBim validation error (esperava bool, recebia null)
   CAUSA: API externa retorna null em vez de false
   SOLUÇÃO: Alterado de bool para Optional[bool] = None
   ARQUIVO: api/schemas.py (linha 72)

3. ERRO: duplicate key constraint violation em projeto_eixo
   CAUSA: API retorna eixos duplicados para o mesmo projeto
   SOLUÇÃO: Deduplicação usando dicionários antes de append
   ARQUIVO: api/services/data_processor.py (linhas 106-139)
   CÓDIGO:
   ```python
   eixos_unicos = {eixo_data.id: eixo_data for eixo_data in projeto_data.eixos}
   for eixo_data in eixos_unicos.values():
       eixo = self.get_or_create_eixo(eixo_data)
       projeto.eixos.append(eixo)
   ```

4. ERRO: SQLAlchemy "should be explicitly declared as text()"
   CAUSA: SQLAlchemy 2.0+ requer text() wrapper para queries literais
   SOLUÇÃO: Import text e usar db.execute(text("SELECT 1"))
   ARQUIVO: api/main.py (linha 7 import, linha 52 uso)

5. ERRO: sync_time validation error (esperava datetime, recebia timedelta)
   CAUSA: datetime.utcnow() - start_time retorna timedelta, não datetime
   SOLUÇÃO: Alterado schema para str e convertido com str()
   ARQUIVO: api/schemas.py (linha 99), api/main.py (linha 93)

================================================================================
CONFIGURAÇÕES DA API EXTERNA
================================================================================

VALORES CONSERVADORES (para evitar rate limiting):
---------------------------------------------------
OBRASGOV_API_BASE_URL=https://api.obrasgov.gestao.gov.br/obrasgov/api
OBRASGOV_API_TIMEOUT=60        # 60 segundos
OBRASGOV_API_MAX_RETRIES=3     # 3 tentativas
OBRASGOV_RETRY_BACKOFF_FACTOR=2  # Exponencial: 1s, 2s, 4s
OBRASGOV_DELAY_BETWEEN_REQUESTS=1  # 1 segundo entre requests

SINCRONIZAÇÃO AUTOMÁTICA:
-------------------------
SYNC_SCHEDULE_HOUR=2   # 2h da manhã UTC
SYNC_SCHEDULE_MINUTE=0

================================================================================
ESTRUTURA DE CÓDIGO (SEPARAÇÃO DE RESPONSABILIDADES)
================================================================================

api/
├── config.py          - Settings com Pydantic, SessionLocal, Base
├── models.py          - 14 models SQLAlchemy (tabelas do banco)
├── schemas.py         - Schemas Pydantic para validação API
├── database.py        - init_db(), drop_db(), reset_db()
├── main.py            - Endpoints FastAPI, orquestração
└── services/
    ├── obrasgov_client.py  - Cliente HTTP assíncrono
    └── data_processor.py   - ETL: process_projeto(), get_or_create_*()

PADRÃO SERVICES:
----------------
- ObrasGovClient: APENAS consumir API externa
- DataProcessor: APENAS transformar e salvar dados
- main.py: APENAS orquestrar e expor endpoints

SEM LOGGING, SEM DOCSTRINGS (decisão do usuário)

================================================================================
ENDPOINTS DA API
================================================================================

GET /health
-----------
Verifica status da API e conexão com PostgreSQL
Resposta: {"status": "ok", "database": "connected", "timestamp": "..."}

POST /sync?uf=DF
----------------
Sincroniza projetos da UF especificada
Resposta: {
  "message": "Sincronização concluída com sucesso para DF",
  "total_projetos": 100,
  "total_executores": 31,
  "total_tomadores": 20,
  "total_repassadores": 25,
  "sync_time": "0:00:27.039667"
}

GET /projetos?skip=0&limit=100&uf=DF
-------------------------------------
Lista projetos com paginação e filtro opcional por UF

GET /projetos/{id_unico}
------------------------
Busca projeto específico por ID único (ex: "4541.53-44")

GET /docs
---------
Documentação interativa Swagger UI

================================================================================
DOCKER SETUP
================================================================================

ARQUIVO: docker-compose.yml
---------------------------
Dois serviços:
1. postgres (PostgreSQL 15 Alpine)
   - Porta 5432
   - Healthcheck com pg_isready
   - Volume postgres_data

2. api (Python 3.11 Slim)
   - Porta 8000
   - depends_on postgres com condition: service_healthy
   - env_file: .env
   - POSTGRES_HOST sobrescrito para "postgres"

COMANDOS ESSENCIAIS:
--------------------
docker compose up -d --build       # Iniciar tudo
docker compose down -v             # Parar e deletar volumes
docker compose up -d --build api   # Rebuildar apenas API
docker logs obrasgov_api -f        # Ver logs da API
docker logs obrasgov_postgres -f   # Ver logs do PostgreSQL

ACESSO AO BANCO:
----------------
docker exec -it obrasgov_postgres psql -U obrasgov_user -d obrasgov_db

QUERIES ÚTEIS:
--------------
docker exec obrasgov_postgres psql -U obrasgov_user -d obrasgov_db -c "\dt"
docker exec obrasgov_postgres psql -U obrasgov_user -d obrasgov_db -c "SELECT COUNT(*) FROM projetos_investimento;"

================================================================================
TESTES REALIZADOS
================================================================================

✅ Health check funcionando
✅ Sincronização de 100 projetos do DF bem-sucedida
✅ 31 executores, 20 tomadores, 25 repassadores cadastrados
✅ Tempo de sincronização: ~27 segundos
✅ Endpoint /projetos listando corretamente
✅ Endpoint /projetos/{id_unico} funcionando
✅ Swagger UI disponível em /docs
✅ 14 tabelas criadas no PostgreSQL
✅ Relacionamentos Many-to-Many funcionando
✅ Deduplicação automática funcionando
✅ BigInteger suportando códigos grandes

================================================================================
DECISÕES DE DESIGN IMPORTANTES
================================================================================

1. SIMPLICIDADE PRIORITÁRIA
   - Usuário pediu "o mais simples possível"
   - Estrutura mínima de arquivos
   - Sem logging (decisão explícita)
   - Sem docstrings (decisão explícita)

2. ROTAS SIMPLES
   - Sem prefixo /api/v1/
   - Direto: /sync, /projetos, /health

3. NORMALIZAÇÃO PARA ANÁLISE
   - 14 tabelas em vez de JSONB
   - Facilita queries SQL complexas
   - Melhor para agregações e JOINs

4. VALORES CONSERVADORES
   - Timeout alto (60s)
   - Retry com backoff
   - Delay entre requests (1s)
   - Evitar rate limiting da API gov

5. DADOS COMO STRING
   - qdt_empregos_gerados: String(50)
   - populacao_beneficiada: String(50)
   - Conversão para int/float na análise, não no banco

6. CEP FORMATADO
   - String(10) em vez de String(8)
   - Mantém formatação com pontos/hífens

================================================================================
ARQUIVO .env (ESTRUTURA)
================================================================================

# Banco de Dados
POSTGRES_USER=obrasgov_user
POSTGRES_PASSWORD=obrasgov_pass
POSTGRES_DB=obrasgov_db
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# API Externa
OBRASGOV_API_BASE_URL=https://api.obrasgov.gestao.gov.br/obrasgov/api
OBRASGOV_API_TIMEOUT=60
OBRASGOV_API_MAX_RETRIES=3
OBRASGOV_RETRY_BACKOFF_FACTOR=2
OBRASGOV_DELAY_BETWEEN_REQUESTS=1

# Sincronização
SYNC_SCHEDULE_HOUR=2
SYNC_SCHEDULE_MINUTE=0

IMPORTANTE: Todos os campos são OBRIGATÓRIOS (sem defaults em Settings)

================================================================================
PRÓXIMOS PASSOS SUGERIDOS
================================================================================

1. Sincronizar TODOS os projetos do DF (não só primeira página)
2. Criar Jupyter Notebook para análise exploratória
3. Implementar visualizações (Matplotlib/Seaborn)
4. Queries SQL para insights:
   - TOP 10 executores por número de projetos
   - Distribuição de valores por repassador
   - Evolução temporal de cadastros
   - Situação dos projetos (em execução, concluído, etc)
5. Filtros avançados nos endpoints (por situação, datas, valores)
6. Endpoint de estatísticas agregadas

================================================================================
COMANDOS PARA ANÁLISE DE DADOS
================================================================================

PANDAS + SQLALCHEMY:
--------------------
```python
import pandas as pd
from sqlalchemy import create_engine

engine = create_engine("postgresql://obrasgov_user:obrasgov_pass@localhost:5432/obrasgov_db")
df = pd.read_sql("SELECT * FROM projetos_investimento", engine)

# Converter campos numéricos
df['empregos'] = pd.to_numeric(df['qdt_empregos_gerados'], errors='coerce')
df['populacao'] = pd.to_numeric(df['populacao_beneficiada'], errors='coerce')

# Análises
print(df.groupby('uf')['empregos'].sum())
print(df['situacao'].value_counts())
```

SQL QUERIES ÚTEIS:
------------------
# Top 10 Executores
SELECT e.nome, COUNT(*) as total_projetos
FROM executores e
JOIN projeto_executor pe ON e.id = pe.executor_id
GROUP BY e.nome
ORDER BY total_projetos DESC
LIMIT 10;

# Valor Total por Repassador
SELECT r.nome, SUM(fr.valor_investimento_previsto) as total
FROM repassadores r
JOIN projeto_repassador pr ON r.id = pr.repassador_id
JOIN fontes_recurso fr ON pr.projeto_id = fr.projeto_id
GROUP BY r.nome;

# Distribuição por Tipo
SELECT t.descricao, COUNT(*) as total
FROM tipos t
JOIN projeto_tipo pt ON t.id = pt.tipo_id
GROUP BY t.descricao;

================================================================================
DICAS DE TROUBLESHOOTING
================================================================================

ERRO: Port already in use
-------------------------
docker ps -a | grep postgres
docker stop <container_name>
docker rm <container_name>

ERRO: Database connection failed
---------------------------------
1. Verificar se postgres está healthy: docker ps
2. Verificar logs: docker logs obrasgov_postgres
3. Testar conexão: docker exec obrasgov_postgres pg_isready

ERRO: API timeout
-----------------
1. Aumentar OBRASGOV_API_TIMEOUT no .env
2. Rebuildar: docker compose up -d --build api

RESETAR TUDO:
-------------
docker compose down -v
docker compose up -d --build

VER ERROS DA API:
-----------------
docker logs obrasgov_api -f

VERIFICAR DADOS:
----------------
docker exec obrasgov_postgres psql -U obrasgov_user -d obrasgov_db -c "
  SELECT
    (SELECT COUNT(*) FROM projetos_investimento) as projetos,
    (SELECT COUNT(*) FROM executores) as executores,
    (SELECT COUNT(*) FROM tomadores) as tomadores,
    (SELECT COUNT(*) FROM repassadores) as repassadores;
"

================================================================================
LIÇÕES APRENDIDAS
================================================================================

1. SEMPRE verificar tamanho real dos dados da API antes de definir tipos
   - Exemplo: códigos eram muito maiores que esperado (BigInteger necessário)

2. APIs externas podem ter dados inconsistentes
   - Campos booleanos podem vir como null
   - Arrays podem ter duplicatas
   - Sempre usar Optional[] e implementar deduplicação

3. SQLAlchemy 2.0 mudou comportamento
   - Queries literais precisam de text() wrapper
   - Sempre consultar docs da versão usada

4. Normalização tem custo inicial mas facilita análises
   - 14 tabelas vs 1 tabela com JSONB
   - Queries SQL muito mais simples
   - JOINs padrão em vez de operações JSONB

5. Docker Compose v2 usa "docker compose" (sem hífen)
   - docker-compose (v1, deprecated)
   - docker compose (v2, atual)

6. Health checks são essenciais para depends_on
   - API só inicia quando PostgreSQL está realmente pronto
   - Evita race conditions

================================================================================
CONTATOS E REFERÊNCIAS
================================================================================

Desenvolvedores: @davi_aguiar_vieira, @mateus_castro3 (Telegram)

Documentação ObrasGov:
https://www.gov.br/transferegov/pt-br/obrasgov/documentacao

Endpoint API:
https://api.obrasgov.gestao.gov.br/obrasgov/api

Arquivos de decisões:
- DECISOES_ARQUITETURA_BD.md (detalhes de todas decisões de DB)
- README.md (documentação completa)
- Este arquivo (notas de desenvolvimento)

================================================================================
FIM DAS NOTAS
================================================================================
